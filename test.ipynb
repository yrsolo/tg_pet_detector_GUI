{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-06T00:48:34.021670Z",
     "start_time": "2025-01-06T00:48:29.972281Z"
    }
   },
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from markdown_it.rules_inline import image\n",
    "from seaborn import histplot\n",
    "from transformers import SamProcessor, SamModel\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.display import display \n",
    "from matplotlib import pyplot as plt\n",
    "from utils import pic2float, pic2int, pic2pil, sigmoid, swimg, display\n",
    "\n",
    "MODEL_NAME = \"facebook/sam-vit-base\"\n",
    "MODEL_NAME = \"facebook/sam-vit-large\"\n",
    "MODEL_NAME = \"facebook/sam-vit-huge\"\n",
    "DTYPE = torch.float16"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T00:48:34.033788Z",
     "start_time": "2025-01-06T00:48:34.024825Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def advanced_mask(logits, threshold=0.5, sigma=5, alpha=10):\n",
    "    \"\"\"\n",
    "    Создает сложную маску с чёткими внутренними объектами и мягкими границами.\n",
    "    \n",
    "    :param logits: Логиты (numpy массив)\n",
    "    :param threshold: Порог для бинаризации\n",
    "    :param sigma: Параметр размытия для сглаживания границ\n",
    "    :param alpha: Коэффициент крутизны для сигмоиды\n",
    "    :return: Маска с плавными границами (numpy массив)\n",
    "    \"\"\"\n",
    "    # 1. Бинаризация логитов\n",
    "    sigmoid = 1 / (1 + np.exp(-logits))  # Преобразуем логиты в вероятности\n",
    "    binary_mask = (sigmoid >= threshold).astype(np.float32)  # Бинарная маска\n",
    "\n",
    "    # 2. Размытие бинарной маски для выделения границ\n",
    "    blurred_binary = cv2.GaussianBlur(binary_mask, (0, 0), sigma)    \n",
    "\n",
    "    # Нормализация размытой маски (для диапазона 0-1)\n",
    "    blurred_binary = 0.25 - (blurred_binary - 0.5) ** 2 \n",
    "    blurred_binary = cv2.GaussianBlur(blurred_binary, (0, 0), sigma)\n",
    "    \n",
    "    \n",
    "    blurred_binary = blurred_binary / np.max(blurred_binary)\n",
    "    blurred_binary = np.clip(blurred_binary, 0, 1)\n",
    "    # print(blurred_binary.max(), blurred_binary.min())\n",
    "    \n",
    "    \n",
    "    # return blurred_binary\n",
    "    # 3. Применение размытой маски к сигмоиде\n",
    "    alpha = 4\n",
    "    soft_mask = 1 / (1 + np.exp(-alpha * (sigmoid - threshold)))  # Сигмоидная маска\n",
    "    soft_mask = 1 * (sigmoid - 0.5) + 0.5 \n",
    "    \n",
    "    # binary_mask = cv2.GaussianBlur(binary_mask, (0, 0), 1)\n",
    "    \n",
    "    final_mask = soft_mask * blurred_binary + binary_mask * (1 - blurred_binary)\n",
    "    final_mask = np.clip(final_mask, 0, 1)\n",
    "\n",
    "    return final_mask\n",
    "\n",
    "def mask_crop(image, mask):\n",
    "    coords = np.where(mask)\n",
    "    y_min, y_max = coords[0].min(), coords[0].max()\n",
    "    x_min, x_max = coords[1].min(), coords[1].max()\n",
    "    return image[y_min:y_max, x_min:x_max], mask[y_min:y_max, x_min:x_max]\n",
    "\n",
    "def center(image, mask, shape = (512, 512), boudary = 0.2):\n",
    "    h, w = shape\n",
    "    bh = int(h * (1-boudary))\n",
    "    bw = int(w * (1-boudary))\n",
    "    obj_h, obj_w, _ = image.shape\n",
    "    scale = min(bh / obj_h, bw / obj_w)\n",
    "    new_h, new_w = int(obj_h * scale), int(obj_w * scale)\n",
    "    # display(pic2pil(image))\n",
    "    if scale < 1:\n",
    "        algo = cv2.INTER_AREA\n",
    "    else:\n",
    "        algo = cv2.INTER_AREA\n",
    "        algo = cv2.INTER_LINEAR \n",
    "        # algo = cv2.INTER_CUBIC\n",
    "        # algo = cv2.INTER_LANCZOS4\n",
    "    \n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=algo)\n",
    "    \n",
    "    mask = cv2.resize(mask, (new_w, new_h))\n",
    "    \n",
    "    top = (h - new_h) // 2\n",
    "    left = (w - new_w) // 2\n",
    "    \n",
    "    new_mask = np.zeros((h, w, 3), dtype=np.float32)\n",
    "    new_mask[top:top+new_h, left:left+new_w] = mask\n",
    "    # \n",
    "    new_image = np.zeros((h, w, 3), dtype=np.float32)\n",
    "    new_image[top:top+new_h, left:left+new_w] = image\n",
    "        \n",
    "    return new_image, new_mask\n",
    "    # return image, mask\n",
    "    "
   ],
   "id": "5cf74aa285cdf9ef",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T00:48:34.774855Z",
     "start_time": "2025-01-06T00:48:34.215651Z"
    }
   },
   "cell_type": "code",
   "source": "model = SamModel.from_pretrained(MODEL_NAME).to()",
   "id": "b44f648bab8f13bd",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T00:48:34.787141Z",
     "start_time": "2025-01-06T00:48:34.782372Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import numpy as np\n",
    "# import requests\n",
    "# from PIL import Image\n",
    "# import io\n",
    "# \n",
    "# def pic2int(image):\n",
    "#     if isinstance(image, torch.Tensor):\n",
    "#         image = image.cpu().detach().numpy()\n",
    "#         \n",
    "#     if isinstance(image, Image.Image):\n",
    "#         image = np.array(image)\n",
    "#     \n",
    "#     pic_max = image.max()\n",
    "#     pic_min = image.min()\n",
    "#     \n",
    "#     if pic_min < 0 or pic_max > 255:\n",
    "#         e = 1e-8\n",
    "#         image = (image - pic_min + e) / (pic_max - pic_min + e)\n",
    "#         pic_max = image.max()        \n",
    "#         \n",
    "#     if pic_max <= 1:\n",
    "#         image = image * 255\n",
    "#     \n",
    "#     return image.astype('uint8')\n",
    "# \n",
    "# def pic2float(image):\n",
    "#     if isinstance(image, Image.Image):\n",
    "#         image = np.array(image)\n",
    "#     \n",
    "#     pic_max = image.max()\n",
    "#     pic_min = image.min()\n",
    "#     \n",
    "#     if pic_min < 0:\n",
    "#         e = 1e-8\n",
    "#         image = (image - pic_min + e) / (pic_max - pic_min + e)\n",
    "#     elif pic_max > 1:\n",
    "#         image = image / 255\n",
    "#     else:\n",
    "#         image = image.astype('float32')\n",
    "#     \n",
    "#     return image\n",
    "#     \n",
    "# def pic2pil(image):\n",
    "#     if isinstance(image, torch.Tensor):\n",
    "#         image = image.cpu().detach().numpy()\n",
    "#     if isinstance(image, np.ndarray):\n",
    "#         image = pic2int(image)\n",
    "#         image = Image.fromarray(image)\n",
    "#     return image\n",
    "# \n",
    "# def swimg(image_arrays, server_url=\"http://127.0.0.1:9002/upload\"):\n",
    "#     \"\"\"\n",
    "#     Отправляет список numpy массивов на сервер Flask.\n",
    "# \n",
    "#     :param image_arrays: Список numpy массивов (изображений)\n",
    "#     :param server_url: URL сервера Flask    \n",
    "#     \"\"\"\n",
    "#     \n",
    "#     image_arrays = [pic2int(i) for i in image_arrays]\n",
    "#     files = []\n",
    "#     # print(image_arrays)\n",
    "# \n",
    "#     for idx, array in enumerate(image_arrays):\n",
    "#         # Преобразуем numpy массив в изображение (если нужно, приводим к uint8)\n",
    "#         #if array.dtype != np.uint8:\n",
    "#         #    array = (array * 255).astype(np.uint8)\n",
    "#         \n",
    "#         # Если изображение черно-белое, добавляем канал\n",
    "#         if len(array.shape) == 2:  # Grayscale (H, W)\n",
    "#             array = np.stack([array] * 3, axis=-1)  # Convert to (H, W, 3)\n",
    "# \n",
    "#         # Преобразуем массив в изображение с помощью PIL\n",
    "#         # print(array.shape, array.min(), array.max(), array.dtype)\n",
    "#         image = Image.fromarray(array)\n",
    "# \n",
    "#         # Сохраняем изображение в буфер памяти\n",
    "#         buffer = io.BytesIO()\n",
    "#         image.save(buffer, format=\"PNG\")\n",
    "#         buffer.seek(0)\n",
    "# \n",
    "#         # Добавляем изображение в список файлов\n",
    "#         files.append(('images', (f'image_{idx}.png', buffer, 'image/png')))\n",
    "# \n",
    "#     # Отправляем POST-запрос с изображениями\n",
    "#     response = requests.post(server_url, files=files)\n",
    "# \n",
    "#     # Проверяем статус\n",
    "#     if response.status_code == 200:\n",
    "#         print(f\"Successfully sent {len(image_arrays)} images to the server!\")\n",
    "#     else:\n",
    "#         print(f\"Failed to send images! Server response: {response.text}\")\n",
    "#         \n",
    "# def sigmoid(x):\n",
    "#     return 1 / (1 + np.exp(-x))\n",
    "# \n"
   ],
   "id": "d284dea4d48bb7dd",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T00:48:34.802490Z",
     "start_time": "2025-01-06T00:48:34.794644Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Predictor():\n",
    "    def __init__(self, model=None, processor=None, device=None, model_name=MODEL_NAME, type=DTYPE):\n",
    "        self.dtype = type\n",
    "\n",
    "        if device is None:\n",
    "            device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.device = device\n",
    "\n",
    "        if model is None:\n",
    "            model = SamModel.from_pretrained(model_name).to(self.dtype).to(self.device)\n",
    "        if processor is None:\n",
    "            processor = SamProcessor.from_pretrained(MODEL_NAME)\n",
    "\n",
    "        self.model = model.to(self.device)\n",
    "        self.processor = processor\n",
    "\n",
    "    def predict(self, image, input_points=None):\n",
    "        image = pic2float(image)\n",
    "\n",
    "        if input_points is None:\n",
    "            input_points = [[[image.shape[1] // 2, image.shape[0] // 2]]]\n",
    "\n",
    "        inputs = self.processor(image, input_points=input_points, return_tensors=\"pt\", do_rescale=False).to(self.dtype).to(\"cuda\")\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            outputs = self.model(**inputs)\n",
    "\n",
    "        scores = outputs.iou_scores[0][0].cpu().detach().numpy().astype('float')\n",
    "        masks = self.processor.image_processor.post_process_masks(\n",
    "            outputs.pred_masks.cpu(),\n",
    "            inputs[\"original_sizes\"].cpu(),\n",
    "            inputs[\"reshaped_input_sizes\"].cpu(),\n",
    "            binarize=False\n",
    "        )[0][0].cpu().numpy().astype('float')\n",
    "\n",
    "        return scores, masks\n",
    "\n",
    "    @staticmethod\n",
    "    def best_masks(scores, masks, n=4):\n",
    "\n",
    "        best_masks = []\n",
    "        best_masks_indexex = np.argsort(scores)[::-1][:n]\n",
    "\n",
    "        for idx in best_masks_indexex:\n",
    "            \n",
    "            mask, score = masks[idx], scores[idx]\n",
    "            mask = advanced_mask(mask)\n",
    "            mask = np.stack([mask, mask, mask], axis=-1)\n",
    "            best_masks.append(mask)\n",
    "        return best_masks\n"
   ],
   "id": "36fd7aff4dd70961",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T00:53:42.892430Z",
     "start_time": "2025-01-06T00:53:42.759166Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#очистка видеопамяти\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# сборщик мусора\n",
    "import gc\n",
    "gc.collect()"
   ],
   "id": "a4e9942b76e9e92c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1060"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T00:48:37.118225Z",
     "start_time": "2025-01-06T00:48:34.810282Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sam_predictor = Predictor()\n",
    "\n",
    "def sam_process(image, text=None):\n",
    "\n",
    "    scores, masks = sam_predictor.predict(image)\n",
    "    masks = sam_predictor.best_masks(scores, masks, 4)\n",
    "\n",
    "    composes = []\n",
    "    crop_masks = []\n",
    "\n",
    "    for mask in masks:\n",
    "        temp_image = image.copy()\n",
    "        temp_image, mask = mask_crop(temp_image, mask)\n",
    "        temp_image, mask = center(temp_image, mask)\n",
    "        bg = np.ones_like(temp_image)\n",
    "        compose = temp_image * mask + (1 - mask) * bg\n",
    "\n",
    "        composes.append(compose)\n",
    "        crop_masks.append(mask)\n",
    "        \n",
    "    return composes, crop_masks, text"
   ],
   "id": "6ac45ec492182cae",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T00:48:37.980694Z",
     "start_time": "2025-01-06T00:48:37.125877Z"
    }
   },
   "cell_type": "code",
   "source": [
    "image_path = \"image.jpg\"\n",
    "image = Image.open(image_path)#.convert(\"RGB\")\n",
    "\n",
    "image = pic2float(image)\n",
    "\n",
    "composes, crop_masks, _ = sam_process(image)\n",
    "swimg(composes)"
   ],
   "id": "95608e1227a39b12",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n",
      "1.0 0.0\n",
      "1.0 0.0\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b99c9630055810c6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T00:48:40.221389Z",
     "start_time": "2025-01-06T00:48:38.090107Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sp = Predictor()\n",
    "\n",
    "image_path = \"image.jpg\"\n",
    "image = Image.open(image_path)#.convert(\"RGB\")\n",
    "\n",
    "input_points = [[[image.size[0]//2, image.size[1]//2]]]\n",
    "input_points"
   ],
   "id": "282cfcbaf8f8c4d7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[150, 100]]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T03:56:32.471513Z",
     "start_time": "2025-01-06T03:56:31.732787Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import kornia\n",
    "import torch\n",
    "import kornia.augmentation as ka\n",
    "\n",
    "from torchvision.transforms import v2\n"
   ],
   "id": "8d225d38555eb635",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T03:56:33.642581Z",
     "start_time": "2025-01-06T03:56:33.626844Z"
    }
   },
   "cell_type": "code",
   "source": [
    "img_type = kornia.io.ImageLoadType.RGB32\n",
    "img = kornia.io.load_image(\"image.jpg\", img_type, \"cpu\")[None]\n",
    "\n",
    "img.cuda()\n"
   ],
   "id": "32dd0d0295ac7aff",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.1451, 0.1412, 0.1373,  ..., 0.0588, 0.0627, 0.0706],\n",
       "          [0.1569, 0.1529, 0.1490,  ..., 0.0627, 0.0667, 0.0745],\n",
       "          [0.1490, 0.1490, 0.1529,  ..., 0.0706, 0.0706, 0.0784],\n",
       "          ...,\n",
       "          [0.9882, 0.9529, 0.9451,  ..., 0.9098, 0.9098, 0.9098],\n",
       "          [0.9451, 0.9137, 0.9412,  ..., 0.9569, 0.9608, 0.9647],\n",
       "          [0.8980, 0.9373, 0.9059,  ..., 0.8039, 0.8235, 0.8392]],\n",
       "\n",
       "         [[0.2588, 0.2549, 0.2431,  ..., 0.0902, 0.1059, 0.1137],\n",
       "          [0.2667, 0.2627, 0.2510,  ..., 0.0941, 0.1098, 0.1176],\n",
       "          [0.2510, 0.2510, 0.2471,  ..., 0.1020, 0.1137, 0.1216],\n",
       "          ...,\n",
       "          [0.9922, 0.9569, 0.9490,  ..., 0.9137, 0.9137, 0.9137],\n",
       "          [0.9490, 0.9176, 0.9451,  ..., 0.9608, 0.9647, 0.9686],\n",
       "          [0.9020, 0.9412, 0.9098,  ..., 0.8078, 0.8275, 0.8431]],\n",
       "\n",
       "         [[0.0863, 0.0824, 0.0824,  ..., 0.0392, 0.0431, 0.0510],\n",
       "          [0.1059, 0.1020, 0.0980,  ..., 0.0431, 0.0549, 0.0549],\n",
       "          [0.0980, 0.0980, 0.1059,  ..., 0.0510, 0.0588, 0.0667],\n",
       "          ...,\n",
       "          [0.9725, 0.9373, 0.9294,  ..., 0.8941, 0.8941, 0.8941],\n",
       "          [0.9294, 0.8980, 0.9255,  ..., 0.9412, 0.9451, 0.9490],\n",
       "          [0.8824, 0.9216, 0.8902,  ..., 0.7882, 0.8078, 0.8235]]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T03:56:38.462243Z",
     "start_time": "2025-01-06T03:56:38.451672Z"
    }
   },
   "cell_type": "code",
   "source": [
    "images = {\n",
    "    'color': torch.cat([img]*8, dim=0).cuda(),\n",
    "    'mask': torch.cat([img]*8, dim=0).cuda(),    \n",
    "}\n",
    "\n",
    "# images['color']"
   ],
   "id": "b43bbbb28274160b",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T04:01:30.053115Z",
     "start_time": "2025-01-06T04:01:29.322422Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import display, pic2pil"
   ],
   "id": "fd6942724f991945",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T04:03:59.166660Z",
     "start_time": "2025-01-06T04:03:59.057674Z"
    }
   },
   "cell_type": "code",
   "source": [
    "r = v2.RandomRotation((00,30), padding_mode='border')\n",
    "\n",
    "a = r(images['color'])\n",
    "\n",
    "sns.histplot(a[2].cpu().detach().numpy().flatten())\n",
    "plt.show()\n",
    "\n",
    "pic2pil(a[2])\n",
    "# sns.histplot(images['color'].cpu().detach().numpy().flatten())\n",
    "# plt.show()"
   ],
   "id": "734fcc723bfee23",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "RandomRotation.__init__() got an unexpected keyword argument 'padding_mode'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[47], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m r \u001B[38;5;241m=\u001B[39m \u001B[43mv2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mRandomRotation\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m00\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m30\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpadding_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mborder\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m a \u001B[38;5;241m=\u001B[39m r(images[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcolor\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m      5\u001B[0m sns\u001B[38;5;241m.\u001B[39mhistplot(a[\u001B[38;5;241m2\u001B[39m]\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mnumpy()\u001B[38;5;241m.\u001B[39mflatten())\n",
      "\u001B[1;31mTypeError\u001B[0m: RandomRotation.__init__() got an unexpected keyword argument 'padding_mode'"
     ]
    }
   ],
   "execution_count": 47
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
